library(dplyr)
library(tidyr)
library(tidyverse)
library(glmnet)
library(ISLR)

# Loading the data
NPS <-read_excel("nps.xlsx")
View(NPS)

NPS = na.omit(NPS)

x = model.matrix(Score~., NPS)[,-1] # trim off the first column
# leaving only the predictors
y = NPS %>%
  select(Score) %>%
  unlist() %>%
  as.numeric()

##create sample/train sets
set.seed(1)

train = NPS %>%
  sample_frac(0.5)

test = NPS %>%
  setdiff(train)

x_train = model.matrix(Score~., train)[,-1]
x_test = model.matrix(Score~., test)[,-1]

y_train = train %>%
  select(Score) %>%
  unlist() %>%
  as.numeric()

y_test = test %>%
  select(Score) %>%
  unlist() %>%
  as.numeric()

lasso_mod = glmnet(x_train, 
                   y_train, 
                   alpha = 1) # Fit lasso model on training data

plot(lasso_mod)    # Draw plot of coefficients

set.seed(1)
cv.out = cv.glmnet(x_train, y_train, alpha = 1) # Fit lasso model on training data
plot(cv.out) # Draw plot of training MSE as a function of lambda
bestlam = cv.out$lambda.min # Select lamda that minimizes training MSE
lasso_pred = predict(lasso_mod, s = bestlam, newx = x_test) # Use best lambda to predict test data
mean((lasso_pred - y_test)^2) # Calculate test MSE

out = glmnet(x, y, alpha = 1) # Fit lasso model on full dataset
lasso_coef = predict(out, type = "coefficients", s = bestlam)[1:13,] # Display coefficients using lambda chosen by CV
lasso_coef

lasso_coef[lasso_coef != 0] # Display only non-zero coefficients
